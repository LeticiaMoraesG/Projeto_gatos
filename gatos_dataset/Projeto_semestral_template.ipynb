{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeticiaMoraesG/Projeto_gatos/blob/main/Projeto_semestral_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40b90843"
      },
      "source": [
        "<img src=\"http://meusite.mackenzie.br/rogerio/mackenzie_logo/UPM.2_horizontal_vermelho.jpg\"  width=300, align=\"right\">\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "# **Template para o Colab do Projeto Semestral**\n",
        "---\n",
        "\n",
        "Atenção, podem ser que nem todas as tarefas sejam executadas no Colab (a aplicação por exemplo, pode estar hospedada no streamlit cloud). Mas a maior parte pode estar aqui ou ao menos indicada e comentada.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Além disso a entrega deve incluir:\n",
        "\n",
        "1. **Um GitHub público do projeto**\n",
        "2. **Código completo e executável em um notebook Python (este template)**\n",
        "3. **Uma aplicação streamlit para consumo do modelo**\n",
        "4. **Um texto/artigo do projeto**\n",
        "5. **Um vídeo (link YouTube ou outro) de no máximo 3min de apresentação do projeto**\n",
        "\n",
        "Um **`readme.md`** no GitHub público do projeto deve indicar (um índice) cada uma dessas entregas.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qR6kcPlTeV_n"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYx9D4GZA5o9",
        "cellView": "form"
      },
      "source": [
        "#@title **Identificação do Grupo**\n",
        "\n",
        "#@markdown Integrantes do Grupo, nome completo em orgem alfabética (*informe \\<RA\\>,\\<nome\\>*)\n",
        "Aluno1 = '10297494 Giovana Ribeiro de Franciso' #@param {type:\"string\"}\n",
        "Aluno2 = '10402951, Leila Akina Ino' #@param {type:\"string\"}\n",
        "Aluno3 = '10400969, Leticia Moraes Gutierrez de Oliveira' #@param {type:\"string\"}\n",
        "Aluno4 = 'None' #@param {type:\"string\"}\n",
        "Aluno5 = 'None' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Assinale aqui a sua opção de Projeto\n",
        "Projeto = \"IA Aplicada a Imagens: Uso de Modelos de Redes Neurais\" #@param [\"IA Aplicada a Imagens: Uso de Modelos de Redes Neurais\", \"IA Aplicada a Documentos: Uso de Grandes Modelos de Linguagem Abertos\"]"
      ],
      "metadata": {
        "id": "-MbC50IHTmh3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Resumo**\n",
        "\n",
        "Apresente um \"abstract\" do seu projeto.\n",
        "\n",
        "1. Objetivo do projeto\n",
        "2. Fontes dos dados e dados originais (coletados)\n",
        "3. Ferramentas/pacotes de IA a serem utilizados para a construção da solução\n",
        "4. Um prévia dos resultados."
      ],
      "metadata": {
        "id": "yxYbSf6mVM7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este projeto tem como objetivo aplicar técnicas de Visão Computacional utilizando Deep Learning para classificar imagens de gatos em quatro raças distintas: Maine Coon, Sphynx, Persa e Siamês. A classificação é realizada por um modelo baseado na arquitetura EfficientNet, treinado com um conjunto de dados organizado em pastas separadas para cada raça, utilizando imagens reais de gatos.\n",
        "\n",
        "As imagens foram coletadas e organizadas manualmente pelo grupo, e estão disponíveis em um repositório no GitHub.\n",
        "\n",
        "O conjunto foi dividido em duas pastas principais:\n",
        "\n",
        "treino/: usado para treinar o modelo\n",
        "\n",
        "teste/: usado para avaliação do desempenho final\n",
        "Cada uma contém subpastas com imagens das quatro raças.\n",
        "\n",
        "Para o desenvolvimento da solução, foram utilizados os seguintes pacotes e frameworks:\n",
        "\n",
        "- Python\n",
        "\n",
        "- TensorFlow / Keras (para criação e treinamento do modelo)\n",
        "\n",
        "- EfficientNet (com pesos pré-treinados no ImageNet)\n",
        "\n",
        "- scikit-learn (para avaliação)\n",
        "\n",
        "- Matplotlib / Seaborn (para visualização)\n",
        "\n",
        "- Streamlit (para criar a aplicação web de classificação de imagens)\n",
        "\n",
        "Como resultado parcial, o modelo não atinge uma acurácia muito boa, devido a poucas imagens no dataset durante a validação, no entando, é capaz de prever com boa confiabilidade a raça de gatos a partir de novas imagens. A aplicação final, desenvolvida com Streamlit, permite que o usuário envie uma imagem e receba a predição da raça com a respectiva confiança do modelo."
      ],
      "metadata": {
        "id": "vZNWUBqJpN0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Apresentação dos dados**\n",
        "\n",
        "[Github do Projeto](https://github.com/LeticiaMoraesG/Projeto_gatos/tree/main)"
      ],
      "metadata": {
        "id": "ctroSu6jNABS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abaixo algumas seções de exemplo\n",
        "\n",
        "> Pode haver mais, dependendo da sua aplicação. Para cada seção faça comentários explicando a tarefa e comentando/sumarizando os resultados."
      ],
      "metadata": {
        "id": "rUPW64ESNJgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install pillow\n",
        "!pip install scikit-learn\n",
        "!pip install seaborn\n",
        "!pip install matplotlib\n",
        "!pip install pandas\n",
        "!pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi1Y5yYKB8aa",
        "outputId": "ea9bfb14-fc8e-43d5-a4c0-fb4a542291eb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "# Imports completos - Execute esta célula DEPOIS da instalação\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import io\n",
        "\n",
        "print(\"Todas as bibliotecas foram importadas com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f6pPBkfCz-l",
        "outputId": "fb35a03d-7529-4052-8e04-a04a67bbd04c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "Todas as bibliotecas foram importadas com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#efficientnet.py"
      ],
      "metadata": {
        "id": "pOEMC8Ab23xX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Importação das Bibliotecas e Configurações Iniciais**\n",
        "Importa todas as bibliotecas necessárias para o projeto de deep learning, visualização e avaliação do modelo e define todas as constantes e parâmetros que serão usados no treinamento, como tamanho das imagens, batch size, número de épocas, etc."
      ],
      "metadata": {
        "id": "kMwRRGYMtRGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# Configurações do modelo e treinamento\n",
        "TAMANHO_IMG = (224, 224)  # Tamanho padrão para EfficientNet\n",
        "TAMANHO_LOTE = 32         # Batch size para treinamento\n",
        "EPOCAS = 10               # Número de épocas para fine-tuning\n",
        "TAXA_APRENDIZADO = 0.001  # Learning rate inicial\n",
        "\n",
        "# Definição das classes (raças de gatos)\n",
        "RACAS = ['maine_coon', 'persa', 'siames', 'sphynx']\n",
        "NUM_RACAS = len(RACAS)\n",
        "\n",
        "# Caminhos dos diretórios de dados\n",
        "PASTA_TREINO = 'treino'\n",
        "PASTA_TESTE = 'teste'"
      ],
      "metadata": {
        "id": "YzKbLezotO6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preparação e transformação dos dados**\n",
        "\n"
      ],
      "metadata": {
        "id": "GDzwn_5AMZ52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Configuração dos Geradores de Dados\n",
        "Cria geradores de dados que aplicam transformações às imagens. Para treino, aplica data augmentation (rotação, zoom, etc.) para aumentar a diversidade dos dados. Para teste, apenas normaliza os pixels."
      ],
      "metadata": {
        "id": "9PIIYFiTuw4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerador para dados de treino com data augmentation\n",
        "# A augmentação ajuda a aumentar a diversidade dos dados e reduzir overfitting\n",
        "gerador_treino = ImageDataGenerator(\n",
        "    rescale=1./255,              # Normalização dos pixels [0,1]\n",
        "    rotation_range=20,           # Rotação aleatória até 20 graus\n",
        "    width_shift_range=0.2,       # Deslocamento horizontal até 20%\n",
        "    height_shift_range=0.2,      # Deslocamento vertical até 20%\n",
        "    horizontal_flip=True,        # Espelhamento horizontal\n",
        "    zoom_range=0.2,              # Zoom aleatório até 20%\n",
        "    shear_range=0.2,             # Cisalhamento até 20%\n",
        "    fill_mode='nearest',         # Preenchimento de pixels vazios\n",
        "    validation_split=0.2         # 20% dos dados para validação\n",
        ")\n",
        "\n",
        "# Gerador para teste (apenas normalização, sem augmentação)\n",
        "gerador_teste = ImageDataGenerator(rescale=1./255)\n"
      ],
      "metadata": {
        "id": "wUxeCXbBurw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Carregamento dos Datasets\n",
        "Carrega os dados de treino, validação e teste usando os geradores configurados. Divide automaticamente os dados de treino em 80% treino e 20% validação."
      ],
      "metadata": {
        "id": "FXzAutxYu5mX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar dados de treinamento (80% dos dados da pasta treino)\n",
        "dados_treino = gerador_treino.flow_from_directory(\n",
        "    PASTA_TREINO,\n",
        "    target_size=TAMANHO_IMG,\n",
        "    batch_size=TAMANHO_LOTE,\n",
        "    class_mode='categorical',    # Para classificação multi-classe\n",
        "    subset='training',\n",
        "    shuffle=True                 # Embaralhar os dados\n",
        ")\n",
        "\n",
        "# Carregar dados de validação (20% dos dados da pasta treino)\n",
        "dados_validacao = gerador_treino.flow_from_directory(\n",
        "    PASTA_TREINO,\n",
        "    target_size=TAMANHO_IMG,\n",
        "    batch_size=TAMANHO_LOTE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False               # Não embaralhar para consistência\n",
        ")\n",
        "\n",
        "# Carregar dados de teste\n",
        "dados_teste = gerador_teste.flow_from_directory(\n",
        "    PASTA_TESTE,\n",
        "    target_size=TAMANHO_IMG,\n",
        "    batch_size=TAMANHO_LOTE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "HutGgZMpus1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Construção do Modelo**"
      ],
      "metadata": {
        "id": "TCbDp5NqvDnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Criação do Modelo\n",
        "Define uma função que cria o modelo usando EfficientNetB0 como backbone (rede base) e adiciona camadas personalizadas para classificação das 4 raças de gatos e compila o modelo definindo o otimizador, função de perda e métricas que serão usadas durante o treinamento."
      ],
      "metadata": {
        "id": "TdlwseebvJez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def criar_modelo():\n",
        "    \"\"\"\n",
        "    Cria o modelo usando EfficientNetB0 como backbone.\n",
        "\n",
        "    Returns:\n",
        "        modelo: Modelo completo para treinamento\n",
        "        modelo_base: Modelo base EfficientNet para fine-tuning\n",
        "    \"\"\"\n",
        "    # Carregar EfficientNetB0 pré-treinado no ImageNet\n",
        "    modelo_base = EfficientNetB0(\n",
        "        weights='imagenet',         # Pesos pré-treinados\n",
        "        include_top=False,          # Remover camadas de classificação\n",
        "        input_shape=(*TAMANHO_IMG, 3)\n",
        "    )\n",
        "\n",
        "    # Congelar as camadas base inicialmente (transfer learning)\n",
        "    modelo_base.trainable = False\n",
        "\n",
        "    # Construir o modelo completo\n",
        "    entradas = tf.keras.Input(shape=(*TAMANHO_IMG, 3))\n",
        "    x = modelo_base(entradas, training=False)  # Features do EfficientNet\n",
        "    x = GlobalAveragePooling2D()(x)            # Pooling global\n",
        "    x = Dropout(0.2)(x)                        # Regularização\n",
        "    x = Dense(128, activation='relu')(x)       # Camada densa intermediária\n",
        "    x = Dropout(0.2)(x)                        # Mais regularização\n",
        "    saidas = Dense(NUM_RACAS, activation='softmax')(x)  # Classificação final\n",
        "\n",
        "    modelo = Model(entradas, saidas)\n",
        "\n",
        "    return modelo, modelo_base\n",
        "\n",
        "# Criar o modelo\n",
        "modelo, modelo_base = criar_modelo()\n",
        "\n",
        "# Compilar o modelo\n",
        "modelo.compile(\n",
        "    optimizer=Adam(learning_rate=TAXA_APRENDIZADO),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Mostrar arquitetura do modelo\n",
        "modelo.summary()"
      ],
      "metadata": {
        "id": "dHW0DWCZvFPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração de Callbacks\n",
        "Define callbacks que monitoram o treinamento e fazem ajustes automáticos, como salvar o melhor modelo, parar o treinamento precocemente se não houver melhoria, e reduzir o learning rate."
      ],
      "metadata": {
        "id": "GlV-49uRvQOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback para salvar o melhor modelo\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'melhor_modelo_raca_gatos.h5',\n",
        "    monitor='val_accuracy',      # Monitorar acurácia de validação\n",
        "    save_best_only=True,         # Salvar apenas o melhor modelo\n",
        "    mode='max',                  # Maximizar a acurácia\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Callback para parada precoce (evitar overfitting)\n",
        "parada_precoce = EarlyStopping(\n",
        "    monitor='val_loss',          # Monitorar perda de validação\n",
        "    patience=5,                  # Parar se não melhorar por 5 épocas\n",
        "    restore_best_weights=True,   # Restaurar melhores pesos\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Callback para reduzir learning rate quando estagnado\n",
        "reduzir_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,                  # Reduzir LR por fator de 0.2\n",
        "    patience=3,                  # Aguardar 3 épocas sem melhoria\n",
        "    min_lr=1e-7,                 # LR mínimo\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "vNB8EPuRvSMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Treinamento de Camadas Superiores**\n",
        "Treina apenas as camadas personalizadas (camadas superiores) enquanto mantém o backbone EfficientNet congelado. Isso é a primeira fase do transfer learning."
      ],
      "metadata": {
        "id": "MHbu5E4Ey2lI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== FASE 1: TREINAMENTO DAS CAMADAS SUPERIORES ===\")\n",
        "print(\"Nesta fase, apenas as camadas personalizadas são treinadas.\")\n",
        "print(\"O backbone EfficientNet permanece congelado.\\n\")\n",
        "\n",
        "# Treinar apenas as camadas superiores (transfer learning)\n",
        "historico = modelo.fit(\n",
        "    dados_treino,\n",
        "    epochs=5,                    # Poucas épocas para esta fase\n",
        "    validation_data=dados_validacao,\n",
        "    callbacks=[checkpoint, parada_precoce, reduzir_lr],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "V7YYQ0MUzBVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fine Tuning do modelo**\n"
      ],
      "metadata": {
        "id": "mnJHmydNNfl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preparação do Fine Tuning\n",
        "Prepara o modelo para a segunda fase (fine-tuning) descongelando as últimas camadas do backbone EfficientNet e reduzindo o learning rate."
      ],
      "metadata": {
        "id": "KHYtpLngzG7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== FASE 2: FINE-TUNING ===\")\n",
        "print(\"Agora vamos descongelar parte do backbone para ajuste fino.\")\n",
        "\n",
        "# Descongelar o modelo base para fine-tuning\n",
        "modelo_base.trainable = True\n",
        "\n",
        "# Determinar quais camadas deixar treináveis (apenas as últimas 20)\n",
        "ajuste_fino_em = len(modelo_base.layers) - 20\n",
        "\n",
        "# Congelar as primeiras camadas, deixar apenas as últimas treináveis\n",
        "for i, camada in enumerate(modelo_base.layers):\n",
        "    if i < ajuste_fino_em:\n",
        "        camada.trainable = False\n",
        "    else:\n",
        "        camada.trainable = True\n",
        "\n",
        "print(f\"- Total de camadas no backbone: {len(modelo_base.layers)}\")\n",
        "print(f\"- Camadas congeladas: {ajuste_fino_em}\")\n",
        "print(f\"- Camadas treináveis: {len(modelo_base.layers) - ajuste_fino_em}\")\n",
        "\n",
        "# Recompilar com learning rate menor para fine-tuning\n",
        "modelo.compile(\n",
        "    optimizer=Adam(learning_rate=TAXA_APRENDIZADO/10),  # LR 10x menor\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "VooEV-TnzMfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Execução\n",
        "Executa a segunda fase do treinamento onde algumas camadas do backbone também são ajustadas com um learning rate menor para um ajuste mais refinado."
      ],
      "metadata": {
        "id": "xzbjyJ9dzSze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Continuar treinamento com fine-tuning\n",
        "historico_ajuste = modelo.fit(\n",
        "    dados_treino,\n",
        "    epochs=EPOCAS,\n",
        "    initial_epoch=len(historico.history['loss']),\n",
        "    validation_data=dados_validacao,\n",
        "    callbacks=[checkpoint, parada_precoce, reduzir_lr]\n",
        ")\n"
      ],
      "metadata": {
        "id": "r5nOiUN5zZJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Avaliação do modelo**\n",
        "\n"
      ],
      "metadata": {
        "id": "p1Evo4PmNhBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Avaliação do Conjunto de teste\n",
        "Avalia o modelo treinado no conjunto de teste (dados nunca vistos durante o treinamento) para medir sua performance real.\n"
      ],
      "metadata": {
        "id": "R3a8iXq1zpU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliar no conjunto de teste\n",
        "print(\"\\nAvaliando no conjunto de teste...\")\n",
        "perda_teste, acuracia_teste = modelo.evaluate(dados_teste)\n",
        "print(f\"Acurácia no teste: {acuracia_teste:.4f}\")\n",
        "print(f\"Perda no teste: {perda_teste:.4f}\")"
      ],
      "metadata": {
        "id": "1P_y00OtzoP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualização do Histórico de Treinamento\n",
        "Cria gráficos mostrando a evolução da acurácia e perda durante o treinamento para visualizar como o modelo aprendeu e identificar possível overfitting."
      ],
      "metadata": {
        "id": "ZQRJr1Ie02ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotar_historico_treinamento(historico, historico_ajuste=None):\n",
        "    \"\"\"\n",
        "    Plota o histórico de treinamento mostrando acurácia e perda.\n",
        "    \"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Combinar históricos se houver fine-tuning\n",
        "    if historico_ajuste:\n",
        "        acuracia = historico.history['accuracy'] + historico_ajuste.history['accuracy']\n",
        "        acuracia_val = historico.history['val_accuracy'] + historico_ajuste.history['val_accuracy']\n",
        "        perda = historico.history['loss'] + historico_ajuste.history['loss']\n",
        "        perda_val = historico.history['val_loss'] + historico_ajuste.history['val_loss']\n",
        "\n",
        "        # Marcar onde começou o fine-tuning\n",
        "        fine_tuning_inicio = len(historico.history['loss'])\n",
        "    else:\n",
        "        acuracia = historico.history['accuracy']\n",
        "        acuracia_val = historico.history['val_accuracy']\n",
        "        perda = historico.history['loss']\n",
        "        perda_val = historico.history['val_loss']\n",
        "        fine_tuning_inicio = None\n",
        "\n",
        "    # Plot acurácia\n",
        "    ax1.plot(acuracia, label='Treino', linewidth=2)\n",
        "    ax1.plot(acuracia_val, label='Validação', linewidth=2)\n",
        "    ax1.set_title('Evolução da Acurácia', fontsize=14, fontweight='bold')\n",
        "    ax1.set_xlabel('Época')\n",
        "    ax1.set_ylabel('Acurácia')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    if fine_tuning_inicio:\n",
        "        ax1.axvline(x=fine_tuning_inicio-0.5, color='red', linestyle='--',\n",
        "                   label='Início Fine-tuning', alpha=0.7)\n",
        "        ax1.legend()\n",
        "\n",
        "    # Plot perda\n",
        "    ax2.plot(perda, label='Treino', linewidth=2)\n",
        "    ax2.plot(perda_val, label='Validação', linewidth=2)\n",
        "    ax2.set_title('Evolução da Perda', fontsize=14, fontweight='bold')\n",
        "    ax2.set_xlabel('Época')\n",
        "    ax2.set_ylabel('Perda')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    if fine_tuning_inicio:\n",
        "        ax2.axvline(x=fine_tuning_inicio-0.5, color='red', linestyle='--',\n",
        "                   label='Início Fine-tuning', alpha=0.7)\n",
        "        ax2.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('historico_treinamento.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Plotar histórico\n",
        "plotar_historico_treinamento(historico, historico_ajuste)"
      ],
      "metadata": {
        "id": "5WuGfZir02j4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Matriz de Confusão e Análise Detalhada\n",
        "Cria uma matriz de confusão para mostrar como o modelo confunde as diferentes raças e gera um relatório detalhado da performance por classe."
      ],
      "metadata": {
        "id": "J4HWMSGT1H5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dados_teste.reset()\n",
        "predicoes = modelo.predict(dados_teste)\n",
        "y_previsto = np.argmax(predicoes, axis=1)\n",
        "y_verdadeiro = dados_teste.classes\n",
        "\n",
        "# Criar matriz de confusão\n",
        "matriz_confusao = confusion_matrix(y_verdadeiro, y_previsto)\n",
        "\n",
        "# Plotar matriz de confusão\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(matriz_confusao, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=RACAS, yticklabels=RACAS)\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.xlabel('Predito')\n",
        "plt.ylabel('Verdadeiro')\n",
        "plt.tight_layout()\n",
        "plt.savefig('matriz_confusao.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f8RxixN91cfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Consumo do modelo**"
      ],
      "metadata": {
        "id": "ViQfwNxkNj0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Função para Predição\n",
        "Define uma função que permite usar o modelo treinado para classificar novas imagens de gatos, mostrando a raça prevista e a confiança da predição."
      ],
      "metadata": {
        "id": "Z2bRXaYA1tCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para fazer predições em novas imagens\n",
        "def prever_raca_gato(caminho_imagem, modelo):\n",
        "    # Carregar e preprocessar a imagem\n",
        "    img = tf.keras.preprocessing.image.load_img(caminho_imagem, target_size=TAMANHO_IMG)\n",
        "    array_img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    array_img = np.expand_dims(array_img, axis=0)\n",
        "    array_img = array_img / 255.0\n",
        "\n",
        "    # Fazer predição\n",
        "    predicoes = modelo.predict(array_img)\n",
        "    indice_classe_prevista = np.argmax(predicoes[0])\n",
        "    classe_prevista = RACAS[indice_classe_prevista]\n",
        "    confianca = predicoes[0][indice_classe_prevista]\n",
        "\n",
        "    # Mostrar resultados\n",
        "    print(f\"\\nPredição para {caminho_imagem}:\")\n",
        "    print(f\"Raça: {classe_prevista}\")\n",
        "    print(f\"Confiança: {confianca:.2%}\")\n",
        "    print(\"\\nProbabilidades para cada raça:\")\n",
        "    for i, raca in enumerate(RACAS):\n",
        "        print(f\"{raca}: {predicoes[0][i]:.2%}\")\n",
        "\n",
        "    return classe_prevista, confianca"
      ],
      "metadata": {
        "id": "iJMWYsC01qIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Relatório de Classificação e Salva o modelo final\n",
        "Salva o modelo treinado em diferentes formatos para uso posterior, incluindo o modelo completo e apenas os pesos."
      ],
      "metadata": {
        "id": "NH00U2Bs14O2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Relatório de classificação\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_verdadeiro, y_previsto, target_names=RACAS))\n",
        "\n",
        "# Salvar o modelo final\n",
        "modelo.save('classificador_racas_gatos_final.h5')\n",
        "print(\"\\nModelo salvo como 'classificador_racas_gatos_final.h5'\")"
      ],
      "metadata": {
        "id": "arHhVfCa14Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#app.py"
      ],
      "metadata": {
        "id": "gLImjRU53gxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Importação das Bibliotecas e Configurações Iniciais**\n",
        "Importa todas as bibliotecas necessárias para o projeto de deep learning, visualização e avaliação do modelo e define todas as constantes."
      ],
      "metadata": {
        "id": "sWASML_J8KzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##import streamlit as st\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import io"
      ],
      "metadata": {
        "id": "hbI57xEm3gYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuração da Aplicação\n",
        "Define título e layout wide do Streamlit, define os parâmetros do modelo e define as 4 raças de gatos que o modelo irá classificar."
      ],
      "metadata": {
        "id": "x4v0iPtB8igb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração da página\n",
        "st.set_page_config(\n",
        "    page_title=\"Classificador de Raças de Gatos\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# Título principal\n",
        "st.title(\"Classificador de Raças de Gatos com EfficientNet\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# Barra lateral\n",
        "st.sidebar.title(\"Configurações\")\n",
        "\n",
        "# Configurações do modelo\n",
        "TAMANHO_IMG = (224, 224)\n",
        "TAMANHO_LOTE = st.sidebar.slider(\"Tamanho do Lote\", 8, 64, 32)\n",
        "EPOCAS = st.sidebar.slider(\"Épocas\", 10, 50, 30)\n",
        "TAXA_APRENDIZADO = st.sidebar.select_slider(\n",
        "    \"Taxa de Aprendizado\",\n",
        "    options=[0.0001, 0.0005, 0.001, 0.005, 0.01],\n",
        "    value=0.001\n",
        ")\n",
        "\n",
        "RACAS = ['maine_coon', 'persa', 'siames', 'sphynx']\n",
        "NUM_RACAS = len(RACAS)\n",
        "\n",
        "EMOJIS_RACAS = {\n",
        "    'maine_coon': '🦁',\n",
        "    'persa': '😸',\n",
        "    'siames': '😼',\n",
        "    'sphynx': '🐈'\n",
        "}"
      ],
      "metadata": {
        "id": "ZwiG10dZ84tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Callback Personalizado para Streamlit\n",
        "Classe herda de tf.keras.callbacks.Callback, mostra progresso do treinamento na interface web, armazena métricas de cada época para análise posterior e atualiza barras de progresso e métricas durante o treinamento"
      ],
      "metadata": {
        "id": "0gnJjzPb88Xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback personalizado para atualizar o Streamlit durante o treinamento\n",
        "class StreamlitCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, progress_bar, metrics_placeholder, epoch_placeholder, total_epochs):\n",
        "        super().__init__()\n",
        "        self.progress_bar = progress_bar\n",
        "        self.metrics_placeholder = metrics_placeholder\n",
        "        self.epoch_placeholder = epoch_placeholder\n",
        "        self.total_epochs = total_epochs\n",
        "        self.history_data = {\n",
        "            'epoca': [],\n",
        "            'perda': [],\n",
        "            'acuracia': [],\n",
        "            'perda_val': [],\n",
        "            'acuracia_val': []\n",
        "        }\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "\n",
        "        # Atualizar progresso\n",
        "        progress = (epoch + 1) / self.total_epochs\n",
        "        self.progress_bar.progress(progress)\n",
        "\n",
        "        # Atualizar época atual\n",
        "        self.epoch_placeholder.markdown(f\"### Época {epoch + 1}/{self.total_epochs}\")\n",
        "\n",
        "        # Guardar dados do histórico\n",
        "        self.history_data['epoca'].append(epoch + 1)\n",
        "        self.history_data['perda'].append(logs.get('loss', 0))\n",
        "        self.history_data['acuracia'].append(logs.get('accuracy', 0))\n",
        "        self.history_data['perda_val'].append(logs.get('val_loss', 0))\n",
        "        self.history_data['acuracia_val'].append(logs.get('val_accuracy', 0))\n",
        "\n",
        "        # Atualizar métricas na interface\n",
        "        col1, col2, col3, col4 = self.metrics_placeholder.columns(4)\n",
        "        col1.metric(\"Perda\", f\"{logs.get('loss', 0):.4f}\")\n",
        "        col2.metric(\"Acurácia\", f\"{logs.get('accuracy', 0):.4f}\")\n",
        "        col3.metric(\"Perda Val\", f\"{logs.get('val_loss', 0):.4f}\")\n",
        "        col4.metric(\"Acurácia Val\", f\"{logs.get('val_accuracy', 0):.4f}\")"
      ],
      "metadata": {
        "id": "mpw9otry89FU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Criação do Modelo\n",
        "Criação do Modelo utilizando EfficientNetB0 pré-treinado no ImageNet; Congela pesos da base (trainable=False), @st.cache_resource evita recriar o modelo desnecessariamente"
      ],
      "metadata": {
        "id": "y909SBBP9k-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@st.cache_resource\n",
        "def criar_modelo():\n",
        "    modelo_base = EfficientNetB0(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(*TAMANHO_IMG, 3)\n",
        "    )\n",
        "    modelo_base.trainable = False\n",
        "\n",
        "    entradas = tf.keras.Input(shape=(*TAMANHO_IMG, 3))\n",
        "    x = modelo_base(entradas, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    saidas = Dense(NUM_RACAS, activation='softmax')(x)\n",
        "\n",
        "    modelo = Model(entradas, saidas)\n",
        "    return modelo, modelo_base"
      ],
      "metadata": {
        "id": "ZpotOXDK9lLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Função de Avaliação\n",
        "Gera probabilidades para cada classe, transforma probabilidades em classes preditas, como matriz de confusão e o relatório de classificação.\n",
        "\n",
        "- Matriz de confusão: Mostra acertos/erros por classe;\n",
        "- Relatório de classificação: Precisão, recall, F1-score por classe."
      ],
      "metadata": {
        "id": "JO9PliyY-CAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_metricas_avaliacao(modelo, dados_teste):\n",
        "    y_pred = modelo.predict(dados_teste, verbose=0)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true = dados_teste.classes\n",
        "    cm = confusion_matrix(y_true, y_pred_classes)\n",
        "    report = classification_report(y_true, y_pred_classes,\n",
        "                                 target_names=RACAS, output_dict=True)\n",
        "\n",
        "    return cm, report, y_pred, y_true"
      ],
      "metadata": {
        "id": "-2D32xl2-BnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dados"
      ],
      "metadata": {
        "id": "J93lHY12-X20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Abas principais\n",
        "aba1, aba2, aba3 = st.tabs([\"📊 Treinamento\", \"🔮 Predição\", \"📈 Análise\"])"
      ],
      "metadata": {
        "id": "4UZtaGs0-55R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Interface de treinamento de IA\n",
        "Verifica diretórios de treino/teste e conta imagens por raça,exibe tabela e gráfico da distribuição do dataset, quando o botão é clicado, processa as imagens, cria o modelo de rede neural, treina com callbacks para monitoramento, mostra gráficos de acurácia/perda durante o treinamento e avalia o modelo no conjunto de teste e grava o modelo treinado em arquivo para uso posterior\n",
        "\n"
      ],
      "metadata": {
        "id": "zSpKdZpe-Zd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with aba1:\n",
        "    st.header(\"Treinamento do Modelo\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        st.subheader(\"📁 Configuração dos Dados\")\n",
        "        diretorio_treino = st.text_input(\"Diretório de Treino\", value=\"treino\")\n",
        "        diretorio_teste = st.text_input(\"Diretório de Teste\", value=\"teste\")\n",
        "\n",
        "        # Verificar se os diretórios existem\n",
        "        if os.path.exists(diretorio_treino) and os.path.exists(diretorio_teste):\n",
        "            st.success(\"✅ Diretórios encontrados!\")\n",
        "\n",
        "            # Contar imagens\n",
        "            contagem_treino = {}\n",
        "            contagem_teste = {}\n",
        "\n",
        "            for raca in RACAS:\n",
        "                caminho_treino = os.path.join(diretorio_treino, raca)\n",
        "                caminho_teste = os.path.join(diretorio_teste, raca)\n",
        "\n",
        "                if os.path.exists(caminho_treino):\n",
        "                    contagem_treino[raca] = len([f for f in os.listdir(caminho_treino)\n",
        "                                               if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "                if os.path.exists(caminho_teste):\n",
        "                    contagem_teste[raca] = len([f for f in os.listdir(caminho_teste)\n",
        "                                              if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "            # Mostrar estatísticas\n",
        "            st.subheader(\"📊 Estatísticas do Dataset\")\n",
        "\n",
        "            df_estatisticas = pd.DataFrame({\n",
        "                'Raça': RACAS,\n",
        "                'Emoji': [EMOJIS_RACAS[raca] for raca in RACAS],\n",
        "                'Treino': [contagem_treino.get(raca, 0) for raca in RACAS],\n",
        "                'Teste': [contagem_teste.get(raca, 0) for raca in RACAS]\n",
        "            })\n",
        "\n",
        "            st.dataframe(df_estatisticas, hide_index=True)\n",
        "\n",
        "            # Gráfico de barras\n",
        "            fig, ax = plt.subplots(figsize=(8, 4))\n",
        "            x = np.arange(len(RACAS))\n",
        "            largura = 0.35\n",
        "\n",
        "            barras1 = ax.bar(x - largura/2, df_estatisticas['Treino'], largura, label='Treino')\n",
        "            barras2 = ax.bar(x + largura/2, df_estatisticas['Teste'], largura, label='Teste')\n",
        "\n",
        "            ax.set_xlabel('Raças')\n",
        "            ax.set_ylabel('Número de Imagens')\n",
        "            ax.set_title('Distribuição do Dataset')\n",
        "            ax.set_xticks(x)\n",
        "            ax.set_xticklabels(RACAS)\n",
        "            ax.legend()\n",
        "\n",
        "            st.pyplot(fig)\n",
        "\n",
        "        else:\n",
        "            st.error(\"❌ Diretórios não encontrados!\")\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"🚀 Iniciar Treinamento\")\n",
        "\n",
        "        if st.button(\"Treinar Modelo\", type=\"primary\"):\n",
        "            if os.path.exists(diretorio_treino) and os.path.exists(diretorio_teste):\n",
        "\n",
        "                try:\n",
        "                    with st.spinner(\"Preparando dados...\"):\n",
        "                        # Criar geradores\n",
        "                        gerador_treino = ImageDataGenerator(\n",
        "                            rescale=1./255,\n",
        "                            rotation_range=20,\n",
        "                            width_shift_range=0.2,\n",
        "                            height_shift_range=0.2,\n",
        "                            horizontal_flip=True,\n",
        "                            zoom_range=0.2,\n",
        "                            shear_range=0.2,\n",
        "                            fill_mode='nearest',\n",
        "                            validation_split=0.2\n",
        "                        )\n",
        "\n",
        "                        gerador_teste = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "                        dados_treino = gerador_treino.flow_from_directory(\n",
        "                            diretorio_treino,\n",
        "                            target_size=TAMANHO_IMG,\n",
        "                            batch_size=TAMANHO_LOTE,\n",
        "                            class_mode='categorical',\n",
        "                            subset='training'\n",
        "                        )\n",
        "\n",
        "                        dados_validacao = gerador_treino.flow_from_directory(\n",
        "                            diretorio_treino,\n",
        "                            target_size=TAMANHO_IMG,\n",
        "                            batch_size=TAMANHO_LOTE,\n",
        "                            class_mode='categorical',\n",
        "                            subset='validation'\n",
        "                        )\n",
        "\n",
        "                        dados_teste = gerador_teste.flow_from_directory(\n",
        "                            diretorio_teste,\n",
        "                            target_size=TAMANHO_IMG,\n",
        "                            batch_size=TAMANHO_LOTE,\n",
        "                            class_mode='categorical',\n",
        "                            shuffle=False\n",
        "                        )\n",
        "\n",
        "                    # Criar modelo\n",
        "                    with st.spinner(\"Criando modelo...\"):\n",
        "                        modelo, modelo_base = criar_modelo()\n",
        "                        modelo.compile(\n",
        "                            optimizer=Adam(learning_rate=TAXA_APRENDIZADO),\n",
        "                            loss='categorical_crossentropy',\n",
        "                            metrics=['accuracy']\n",
        "                        )\n",
        "\n",
        "                    # Callbacks\n",
        "                    checkpoint = ModelCheckpoint(\n",
        "                        'melhor_modelo_racas_gatos.h5',\n",
        "                        monitor='val_accuracy',\n",
        "                        save_best_only=True,\n",
        "                        mode='max',\n",
        "                        verbose=1\n",
        "                    )\n",
        "\n",
        "                    parada_precoce = EarlyStopping(\n",
        "                        monitor='val_loss',\n",
        "                        patience=5,\n",
        "                        restore_best_weights=True,\n",
        "                        verbose=1\n",
        "                    )\n",
        "\n",
        "                    # Placeholders para métricas\n",
        "                    espaco_epoca = st.empty()\n",
        "                    espaco_metricas = st.empty()\n",
        "                    barra_progresso = st.progress(0)\n",
        "\n",
        "                    # Callback personalizado para Streamlit\n",
        "                    callback_streamlit = StreamlitCallback(\n",
        "                        barra_progresso, espaco_metricas, espaco_epoca, EPOCAS\n",
        "                    )\n",
        "\n",
        "                    st.info(\"🏃 Treinamento em andamento...\")\n",
        "\n",
        "                    historico = modelo.fit(\n",
        "                        dados_treino,\n",
        "                        epochs=EPOCAS,\n",
        "                        validation_data=dados_validacao,\n",
        "                        callbacks=[checkpoint, parada_precoce, callback_streamlit],\n",
        "                        verbose=0\n",
        "                    )\n",
        "\n",
        "                    st.success(\"✅ Treinamento concluído!\")\n",
        "\n",
        "                    # Salvar histórico no session state\n",
        "                    st.session_state['historico_treinamento'] = callback_streamlit.history_data\n",
        "                    st.session_state['modelo_treinado'] = True\n",
        "                    st.session_state['modelo'] = modelo\n",
        "                    st.session_state['dados_teste'] = dados_teste\n",
        "\n",
        "                    # Plotar gráficos do histórico real\n",
        "                    st.subheader(\"📈 Histórico de Treinamento\")\n",
        "\n",
        "                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "                    # Acurácia\n",
        "                    ax1.plot(callback_streamlit.history_data['epoca'],\n",
        "                            callback_streamlit.history_data['acuracia'], label='Treino')\n",
        "                    ax1.plot(callback_streamlit.history_data['epoca'],\n",
        "                            callback_streamlit.history_data['acuracia_val'], label='Validação')\n",
        "                    ax1.set_xlabel('Época')\n",
        "                    ax1.set_ylabel('Acurácia')\n",
        "                    ax1.set_title('Acurácia por Época')\n",
        "                    ax1.legend()\n",
        "                    ax1.grid(True)\n",
        "\n",
        "                    # Perda\n",
        "                    ax2.plot(callback_streamlit.history_data['epoca'],\n",
        "                            callback_streamlit.history_data['perda'], label='Treino')\n",
        "                    ax2.plot(callback_streamlit.history_data['epoca'],\n",
        "                            callback_streamlit.history_data['perda_val'], label='Validação')\n",
        "                    ax2.set_xlabel('Época')\n",
        "                    ax2.set_ylabel('Perda')\n",
        "                    ax2.set_title('Perda por Época')\n",
        "                    ax2.legend()\n",
        "                    ax2.grid(True)\n",
        "\n",
        "                    st.pyplot(fig)\n",
        "\n",
        "                    # Salvar modelo\n",
        "                    modelo.save('classificador_racas_gatos_streamlit.h5')\n",
        "\n",
        "                    # Avaliar no conjunto de teste\n",
        "                    with st.spinner(\"Avaliando modelo no conjunto de teste...\"):\n",
        "                        avaliacao = modelo.evaluate(dados_teste, verbose=0)\n",
        "                        st.session_state['avaliacao_teste'] = {\n",
        "                            'perda': avaliacao[0],\n",
        "                            'acuracia': avaliacao[1]\n",
        "                        }\n",
        "\n",
        "                        # Calcular métricas detalhadas\n",
        "                        cm, report, y_pred, y_true = calcular_metricas_avaliacao(modelo, dados_teste)\n",
        "                        st.session_state['matriz_confusao'] = cm\n",
        "                        st.session_state['relatorio_classificacao'] = report\n",
        "\n",
        "                    st.success(f\"🎯 Acurácia no teste: {avaliacao[1]:.1%}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    st.error(f\"❌ Erro durante o treinamento: {str(e)}\")\n",
        "                    st.exception(e)\n",
        "\n",
        "            else:\n",
        "                st.error(\"Por favor, verifique os diretórios de dados!\")"
      ],
      "metadata": {
        "id": "g29XX2Q4-ZHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Identificador de raças de gatos\n",
        "Verifica se existe um modelo treinado na sessão ou salvo em arquivo, permite upload de imagem de gato (JPG, JPEG, PNG), redimensiona e ajusta a foto para o formato que o modelo entende, usa o modelo de IA para identificar a raça do gato, exibe a raça identificada, confiança e gráfico com todas as probabilidades e apresenta curiosidades sobre a raça identificada"
      ],
      "metadata": {
        "id": "B-dAzhu9_uDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with aba2:\n",
        "    st.header(\"Predição de Raça\")\n",
        "\n",
        "    # Verificar se existe modelo treinado\n",
        "    caminho_modelo = 'classificador_racas_gatos_streamlit.h5'\n",
        "\n",
        "    modelo = None\n",
        "    if 'modelo' in st.session_state:\n",
        "        modelo = st.session_state['modelo']\n",
        "        st.success(\"✅ Modelo da sessão carregado!\")\n",
        "    elif os.path.exists(caminho_modelo):\n",
        "        # Carregar modelo\n",
        "        @st.cache_resource\n",
        "        def carregar_modelo():\n",
        "            return tf.keras.models.load_model(caminho_modelo)\n",
        "\n",
        "        modelo = carregar_modelo()\n",
        "        st.success(\"✅ Modelo salvo carregado!\")\n",
        "\n",
        "    if modelo is not None:\n",
        "        # Upload de imagem\n",
        "        arquivo_enviado = st.file_uploader(\n",
        "            \"Escolha uma imagem de gato\",\n",
        "            type=['jpg', 'jpeg', 'png'],\n",
        "            help=\"Formatos suportados: JPG, JPEG, PNG\"\n",
        "        )\n",
        "\n",
        "        if arquivo_enviado is not None:\n",
        "            # Mostrar imagem\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                st.subheader(\"📷 Imagem Original\")\n",
        "                imagem = Image.open(arquivo_enviado)\n",
        "                st.image(imagem, use_column_width=True)\n",
        "                st.caption(f\"Dimensões: {imagem.size[0]} x {imagem.size[1]}\")\n",
        "                st.caption(f\"Formato: {imagem.format}\")\n",
        "\n",
        "            with col2:\n",
        "                st.subheader(\"🔮 Predição\")\n",
        "\n",
        "                # Preprocessar imagem\n",
        "                img = imagem.resize(TAMANHO_IMG)\n",
        "                array_img = np.array(img)\n",
        "\n",
        "                # Verificar se a imagem tem 3 canais (RGB)\n",
        "                if len(array_img.shape) == 2:\n",
        "                    array_img = np.stack([array_img] * 3, axis=-1)\n",
        "                elif array_img.shape[2] == 4:\n",
        "                    array_img = array_img[:, :, :3]\n",
        "\n",
        "                array_img = np.expand_dims(array_img, axis=0)\n",
        "                array_img = array_img / 255.0\n",
        "\n",
        "                with st.spinner(\"Analisando...\"):\n",
        "                    predicoes = modelo.predict(array_img, verbose=0)\n",
        "                    indice_predito = np.argmax(predicoes[0])\n",
        "                    raca_predita = RACAS[indice_predito]\n",
        "                    confianca = predicoes[0][indice_predito]\n",
        "\n",
        "                # Mostrar resultado principal\n",
        "                st.markdown(f\"### {EMOJIS_RACAS[raca_predita]} {raca_predita.replace('_', ' ').title()}\")\n",
        "                st.markdown(f\"**Confiança:** {confianca:.1%}\")\n",
        "\n",
        "                # Barra de progresso para confiança\n",
        "                st.progress(float(confianca))\n",
        "\n",
        "                # Mostrar todas as probabilidades\n",
        "                st.markdown(\"#### Probabilidades por Raça:\")\n",
        "\n",
        "                # Criar DataFrame com resultados\n",
        "                df_resultados = pd.DataFrame({\n",
        "                    'Raça': [f\"{EMOJIS_RACAS[raca]} {raca.replace('_', ' ').title()}\" for raca in RACAS],\n",
        "                    'Probabilidade': [f\"{predicoes[0][i]:.1%}\" for i in range(NUM_RACAS)],\n",
        "                    'Score': predicoes[0]\n",
        "                })\n",
        "                df_resultados = df_resultados.sort_values('Score', ascending=False)\n",
        "\n",
        "                # Mostrar como gráfico de barras\n",
        "                fig, ax = plt.subplots(figsize=(8, 4))\n",
        "                barras = ax.barh(df_resultados['Raça'], df_resultados['Score'])\n",
        "\n",
        "                # Colorir a barra com maior probabilidade\n",
        "                cores = ['#1f77b4' if i != 0 else '#ff7f0e' for i in range(len(barras))]\n",
        "                for barra, cor in zip(barras, cores):\n",
        "                    barra.set_color(cor)\n",
        "\n",
        "                ax.set_xlabel('Probabilidade')\n",
        "                ax.set_xlim(0, 1)\n",
        "                ax.set_title('Distribuição de Probabilidades')\n",
        "\n",
        "                # Adicionar valores nas barras\n",
        "                for i, (raca, score) in enumerate(zip(df_resultados['Raça'], df_resultados['Score'])):\n",
        "                    ax.text(score + 0.01, i, f'{score:.1%}', va='center')\n",
        "\n",
        "                st.pyplot(fig)\n",
        "\n",
        "                # Informações adicionais sobre a raça\n",
        "                info_racas = {\n",
        "                    'maine_coon': \"O Maine Coon é uma das maiores raças de gatos domésticos. São conhecidos por serem gentis gigantes, muito sociáveis e brincalhões.\",\n",
        "                    'persa': \"O gato Persa é conhecido por sua pelagem longa e luxuosa e face achatada. São gatos calmos, gentis e afetuosos.\",\n",
        "                    'siames': \"O gato Siamês é uma raça elegante conhecida por seus olhos azuis e pelagem clara com extremidades escuras. São muito vocais e inteligentes.\",\n",
        "                    'sphynx': \"O Sphynx é conhecido por ser 'sem pelos' (na verdade tem uma fina camada de penugem). São gatos muito afetuosos e energéticos.\"\n",
        "                }\n",
        "\n",
        "                with st.expander(f\"ℹ️ Sobre {raca_predita.replace('_', ' ').title()}\"):\n",
        "                    st.write(info_racas.get(raca_predita, \"Informação não disponível.\"))\n",
        "\n",
        "    else:\n",
        "        st.warning(\"⚠️ Nenhum modelo treinado encontrado. Por favor, treine um modelo primeiro na aba 'Treinamento'.\")"
      ],
      "metadata": {
        "id": "otlXMxti_uPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Análise do Modelo\n",
        "Exibe acurácia, perda, precisão e recall do modelo em cartões visuais,cria um mapa de calor mostrando onde o modelo acerta e erra cada raça, apresenta tabela com precisão, recall e F1-score de cada raça individualmente,compara visualmente as métricas de todas as raças em formato circular, exibe gráficos da evolução do treinamento e detecta possível overfitting e mostra se o modelo decorou os dados de treino ao invés de aprender"
      ],
      "metadata": {
        "id": "T9GuJ-BdAil6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with aba3:\n",
        "    st.header(\"Análise do Modelo\")\n",
        "\n",
        "    if st.session_state.get('modelo_treinado', False) and 'avaliacao_teste' in st.session_state:\n",
        "\n",
        "        # Métricas\n",
        "        st.subheader(\"📊 Métricas de Performance\")\n",
        "\n",
        "        avaliacao = st.session_state['avaliacao_teste']\n",
        "        relatorio = st.session_state.get('relatorio_classificacao', {})\n",
        "\n",
        "        col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "        # Valores do modelo\n",
        "        acuracia_final = avaliacao['acuracia']\n",
        "        perda_final = avaliacao['perda']\n",
        "\n",
        "        # Calcular precisão e recall médios\n",
        "        if relatorio and 'macro avg' in relatorio:\n",
        "            precisao_media = relatorio['macro avg']['precision']\n",
        "            recall_medio = relatorio['macro avg']['recall']\n",
        "        else:\n",
        "            precisao_media = acuracia_final\n",
        "            recall_medio = acuracia_final\n",
        "\n",
        "        col1.metric(\"Acurácia Final\", f\"{acuracia_final:.1%}\")\n",
        "        col2.metric(\"Perda Final\", f\"{perda_final:.3f}\")\n",
        "        col3.metric(\"Precisão Média\", f\"{precisao_media:.1%}\")\n",
        "        col4.metric(\"Recall Médio\", f\"{recall_medio:.1%}\")\n",
        "\n",
        "        # Matriz de Confusão\n",
        "        if 'matriz_confusao' in st.session_state:\n",
        "            st.subheader(\"🎯 Matriz de Confusão\")\n",
        "\n",
        "            matriz_confusao = st.session_state['matriz_confusao']\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(8, 6))\n",
        "            sns.heatmap(matriz_confusao, annot=True, fmt='d', cmap='Blues',\n",
        "                        xticklabels=RACAS, yticklabels=RACAS, ax=ax)\n",
        "            ax.set_title('Matriz de Confusão')\n",
        "            ax.set_xlabel('Predito')\n",
        "            ax.set_ylabel('Verdadeiro')\n",
        "            st.pyplot(fig)\n",
        "\n",
        "        # Métricas por classe\n",
        "        if relatorio:\n",
        "            st.subheader(\"📈 Performance por Raça\")\n",
        "\n",
        "            dados_metricas = {\n",
        "                'Raça': [f\"{EMOJIS_RACAS[raca]} {raca.replace('_', ' ').title()}\" for raca in RACAS],\n",
        "                'Precisão': [relatorio.get(raca, {}).get('precision', 0) for raca in RACAS],\n",
        "                'Recall': [relatorio.get(raca, {}).get('recall', 0) for raca in RACAS],\n",
        "                'F1-Score': [relatorio.get(raca, {}).get('f1-score', 0) for raca in RACAS]\n",
        "            }\n",
        "\n",
        "            df_metricas = pd.DataFrame(dados_metricas)\n",
        "\n",
        "            # Mostrar tabela\n",
        "            st.dataframe(\n",
        "                df_metricas.style.format({\n",
        "                    'Precisão': '{:.1%}',\n",
        "                    'Recall': '{:.1%}',\n",
        "                    'F1-Score': '{:.1%}'\n",
        "                }),\n",
        "                hide_index=True\n",
        "            )\n",
        "\n",
        "            # Gráfico radar com dados\n",
        "            st.subheader(\"🕸️ Comparação de Métricas\")\n",
        "\n",
        "            categorias = ['Precisão', 'Recall', 'F1-Score']\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(8, 6), subplot_kw=dict(projection='polar'))\n",
        "\n",
        "            angulos = np.linspace(0, 2 * np.pi, len(categorias), endpoint=False).tolist()\n",
        "            angulos += angulos[:1]\n",
        "\n",
        "            for idx, raca in enumerate(RACAS):\n",
        "                valores = [dados_metricas['Precisão'][idx],\n",
        "                          dados_metricas['Recall'][idx],\n",
        "                          dados_metricas['F1-Score'][idx]]\n",
        "                valores += valores[:1]\n",
        "\n",
        "                ax.plot(angulos, valores, 'o-', linewidth=2,\n",
        "                       label=f\"{EMOJIS_RACAS[raca]} {raca.replace('_', ' ').title()}\")\n",
        "                ax.fill(angulos, valores, alpha=0.15)\n",
        "\n",
        "            ax.set_theta_offset(np.pi / 2)\n",
        "            ax.set_theta_direction(-1)\n",
        "            ax.set_xticks(angulos[:-1])\n",
        "            ax.set_xticklabels(categorias)\n",
        "            ax.set_ylim(0, 1)\n",
        "            ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
        "            ax.set_yticklabels(['20%', '40%', '60%', '80%', '100%'])\n",
        "            ax.grid(True)\n",
        "            ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
        "\n",
        "            st.pyplot(fig)\n",
        "\n",
        "        # Mostrar histórico de treinamento\n",
        "        if 'historico_treinamento' in st.session_state:\n",
        "            st.subheader(\"📈 Histórico de Treinamento Detalhado\")\n",
        "\n",
        "            historico = st.session_state['historico_treinamento']\n",
        "\n",
        "            # Criar gráficos do histórico\n",
        "            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "            # Acurácia\n",
        "            ax1.plot(historico['epoca'], historico['acuracia'], label='Treino', marker='o')\n",
        "            ax1.plot(historico['epoca'], historico['acuracia_val'], label='Validação', marker='s')\n",
        "            ax1.set_xlabel('Época')\n",
        "            ax1.set_ylabel('Acurácia')\n",
        "            ax1.set_title('Acurácia por Época')\n",
        "            ax1.legend()\n",
        "            ax1.grid(True)\n",
        "\n",
        "            # Perda\n",
        "            ax2.plot(historico['epoca'], historico['perda'], label='Treino', marker='o')\n",
        "            ax2.plot(historico['epoca'], historico['perda_val'], label='Validação', marker='s')\n",
        "            ax2.set_xlabel('Época')\n",
        "            ax2.set_ylabel('Perda')\n",
        "            ax2.set_title('Perda por Época')\n",
        "            ax2.legend()\n",
        "            ax2.grid(True)\n",
        "\n",
        "            # Diferença entre treino e validação (Overfitting)\n",
        "            diff_acc = np.array(historico['acuracia']) - np.array(historico['acuracia_val'])\n",
        "            ax3.plot(historico['epoca'], diff_acc, marker='o', color='red')\n",
        "            ax3.set_xlabel('Época')\n",
        "            ax3.set_ylabel('Diferença de Acurácia')\n",
        "            ax3.set_title('Overfitting (Treino - Validação)')\n",
        "            ax3.grid(True)\n",
        "            ax3.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "\n",
        "            ax4.bar(range(len(RACAS)), [1]*len(RACAS), color=['blue', 'green', 'red', 'orange'])\n",
        "            ax4.set_xlabel('Raças')\n",
        "            ax4.set_ylabel('Normalizado')\n",
        "            ax4.set_title('Distribuição de Classes')\n",
        "            ax4.set_xticks(range(len(RACAS)))\n",
        "            ax4.set_xticklabels(RACAS, rotation=45)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            st.pyplot(fig)\n",
        "\n",
        "    else:\n",
        "        st.warning(\"⚠️ Nenhum modelo treinado encontrado. Por favor, treine um modelo primeiro.\")"
      ],
      "metadata": {
        "id": "jF62AmLfAiwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Referências**\n",
        "\n",
        "Este é um item obrigatório. Inclua aqui o as referências, fontes, ou bibliografia e sites/bibliotecas que foram empregados para construir a sua proposta.\n",
        "\n",
        "Gutierrez, L. M. Projeto Gatos. 2024. Repositório GitHub. Disponível em: https://github.com/LeticiaMoraesG/Projeto_gatos/tree/main. Acesso em: 20 mai. 2025.\n",
        "KERAS. EfficientNet. In: Keras Applications Documentation. Disponível em: https://keras.io/api/applications/efficientnet/. Acesso em: 27 mai. 2025.\n",
        "STREAMLIT. Streamlit: The fastest way to build and share data apps. Disponível em: https://streamlit.io/. Acesso em: 27 mai. 2025.\n",
        "TAN, M. et al. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. arXiv preprint arXiv:1905.11946, 2019. Disponível em: https://arxiv.org/abs/1905.11946. Acesso em: 28 mai. 2025.\n",
        "TENSORFLOW. TensorFlow: An end-to-end open source machine learning platform. Disponível em: https://www.tensorflow.org/. Acesso em: 27 mai. 2025."
      ],
      "metadata": {
        "id": "7LtXrRFr4hg3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8crUBC3IQ3U_"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BluFtfHuCGzm",
        "cellView": "form"
      },
      "source": [
        "#@title **Avaliação**\n",
        "GitHub = 10 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Implementacao_Model_Code = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Aplicacao_Streamlit = 9 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Texto_Artigo  = 6 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Video = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Geral = 7 #@param {type:\"slider\", min:0, max:10, step:1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "2Gqw7hUZHyle",
        "cellView": "form",
        "outputId": "cf56d67f-e7bc-42f0-a81d-f1f808967e93"
      },
      "source": [
        "#@title **Nota Final**\n",
        "\n",
        "nota = 2*GitHub + 4*Implementacao_Model_Code + 2*Aplicacao_Streamlit + 1*Texto_Artigo + 1*Video\n",
        "\n",
        "nota = nota / 10\n",
        "\n",
        "print(f'Nota final do trabalho {nota :.1f}')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "alunos = pd.DataFrame()\n",
        "\n",
        "lista_tia = []\n",
        "lista_nome = []\n",
        "\n",
        "for i in range(1,6):\n",
        "  exec(\"if Aluno\" + str(i) + \" !='None':  lista = Aluno\" + str(i) + \".split(','); lista_tia.append(lista[0]); lista_nome.append(lista[1].upper())\")\n",
        "\n",
        "alunos['tia'] = lista_tia\n",
        "alunos['nome'] = lista_nome\n",
        "alunos['nota'] = np.round(nota,1)\n",
        "print()\n",
        "display(alunos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nota final do trabalho 7.9\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       tia              nome  nota\n",
              "0  1115665    ADRIANA FUJITA   7.9\n",
              "1  1115677   DANIEL HENRIQUE   7.9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0360d6d-a298-4195-9914-febf9bafcd63\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tia</th>\n",
              "      <th>nome</th>\n",
              "      <th>nota</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1115665</td>\n",
              "      <td>ADRIANA FUJITA</td>\n",
              "      <td>7.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1115677</td>\n",
              "      <td>DANIEL HENRIQUE</td>\n",
              "      <td>7.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0360d6d-a298-4195-9914-febf9bafcd63')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b0360d6d-a298-4195-9914-febf9bafcd63 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b0360d6d-a298-4195-9914-febf9bafcd63');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-120aa0b0-48d8-4778-aca7-bace2443a5e8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-120aa0b0-48d8-4778-aca7-bace2443a5e8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-120aa0b0-48d8-4778-aca7-bace2443a5e8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c5110ba6-c42d-43ec-931e-d08b9033ac7e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('alunos')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c5110ba6-c42d-43ec-931e-d08b9033ac7e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('alunos');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "alunos",
              "summary": "{\n  \"name\": \"alunos\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"tia\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1115677\",\n          \"1115665\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nome\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" DANIEL HENRIQUE\",\n          \" ADRIANA FUJITA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nota\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 7.9,\n        \"max\": 7.9,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}
